"""LLMãƒ™ãƒ¼ã‚¹ã®è«–æ–‡è¦ç´„æ©Ÿèƒ½

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å«ã‚€
OpenAIã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸç ”ç©¶è«–æ–‡ã®æ—¥æœ¬èªè¦ç´„ç”Ÿæˆã‚’å‡¦ç†ã—ã¾ã™ã€‚
"""

import openai
import time
from typing import Dict, Optional
import logging


class LLMSummarizer:
    """OpenAI LLMã‚’ä½¿ç”¨ã—ã¦ç ”ç©¶è«–æ–‡ã®æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã‚¯ãƒ©ã‚¹
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯ã€OpenAIã®APIã¨ã®ç›¸äº’ä½œç”¨ã‚’ç®¡ç†ã—ã€é©åˆ‡ãª
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ã‚’å«ã‚€
    ç ”ç©¶è«–æ–‡ã®æ§‹é€ åŒ–ã•ã‚ŒãŸæ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    
    å±æ€§:
        config: APIè¨­å®šã‚’å«ã‚€è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        logger (logging.Logger): ã“ã®ã‚¯ãƒ©ã‚¹ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    
    def __init__(self, config) -> None:
        """LLMè¦ç´„ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–
        
        å¼•æ•°:
            config: OpenAI APIã‚­ãƒ¼ã¨è¨­å®šã‚’å«ã‚€è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        ä¾‹å¤–:
            ValueError: OpenAI APIã‚­ãƒ¼ãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        if not config.OPENAI_API_KEY:
            raise ValueError("è¦ç´„å‡¦ç†ã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
            
        openai.api_key = config.OPENAI_API_KEY
    
    def summarize_paper(self, paper: Dict) -> Dict:
        """ç ”ç©¶è«–æ–‡ã®æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆ
        
        å¼•æ•°:
            paper (Dict): ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã€è‘—è€…ç­‰ã‚’å«ã‚€è«–æ–‡è¾æ›¸
            
        æˆ»ã‚Šå€¤:
            Dict: æ—¥æœ¬èªè¦ç´„ãŒè¿½åŠ ã•ã‚ŒãŸæ›´æ–°ã•ã‚ŒãŸè«–æ–‡è¾æ›¸
            
        ä¾‹å¤–:
            SummarizationError: è¦ç´„ç”ŸæˆãŒå¤±æ•—ã—ãŸå ´åˆ
        """
        if not self._validate_paper_data(paper):
            self.logger.warning(f"è¦ç´„å‡¦ç†ç”¨ã®ç„¡åŠ¹ãªè«–æ–‡ãƒ‡ãƒ¼ã‚¿: {paper.get('id', 'unknown')}")
            paper['summary_ja'] = "è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒ¼ã‚¿ä¸å‚™ï¼‰"
            paper['summary_generated'] = False
            return paper
        
        # é›»åŠ›é–¢é€£åº¦ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆäº‹å‰ã«è©•ä¾¡æ¸ˆã¿ã®å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
        power_relevance = paper.get('power_relevance_score')
        if power_relevance is None:
            power_relevance = self._assess_power_relevance(paper)
        
        if power_relevance < 0.3:  # é–¢é€£åº¦ãŒä½ã„å ´åˆã¯è¦ç´„ã‚’ã‚¹ã‚­ãƒƒãƒ—
            self.logger.info(f"é›»åŠ›é–¢é€£åº¦ãŒä½ã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {paper.get('title', '')[:50]}")
            paper['summary_ja'] = "é›»åŠ›åˆ†é‡ã¸ã®é–¢é€£åº¦ãŒä½ã„ãŸã‚è¦ç´„å¯¾è±¡å¤–"
            paper['summary_generated'] = False
            paper['power_relevance'] = power_relevance
            return paper
        
        try:
            prompt = self._create_summary_prompt(paper)
            summary = self._generate_summary_with_retry(prompt, max_retries=3)
            
            paper_with_summary = paper.copy()
            paper_with_summary['summary_ja'] = summary
            paper_with_summary['summary_generated'] = True
            paper_with_summary['power_relevance'] = power_relevance
            
            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿ã®ãŸã‚ã®å¾…æ©Ÿ
            time.sleep(1)
            
            self.logger.info(f"è«–æ–‡ã®è¦ç´„ç”ŸæˆãŒæˆåŠŸã—ã¾ã—ãŸ: {paper['id']}")
            return paper_with_summary
            
        except Exception as e:
            self.logger.error(f"è«–æ–‡'{paper.get('title', '')[:50]}...'ã®è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            paper['summary_ja'] = "è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            paper['summary_generated'] = False
            paper['power_relevance'] = power_relevance
            return paper
    
    def _generate_summary_with_retry(self, prompt: str, max_retries: int = 3) -> str:
        """APIå¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãè¦ç´„ç”Ÿæˆ
        
        å¼•æ•°:
            prompt (str): LLMã«é€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            max_retries (int): æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
            
        æˆ»ã‚Šå€¤:
            str: ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
            
        ä¾‹å¤–:
            SummarizationError: å…¨ã¦ã®ãƒªãƒˆãƒ©ã‚¤è©¦è¡ŒãŒå¤±æ•—ã—ãŸå ´åˆ
        """
        last_exception = None
        
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    # model="gpt-3.5-turbo",
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "system", 
                            "content": 
                            """
                            ã‚ãªãŸã¯é›»åŠ›ã‚·ã‚¹ãƒ†ãƒ ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼äºˆæ¸¬ãƒ»AIæŠ€è¡“ã®å°‚é–€ç ”ç©¶è€…ã§ã™ã€‚
                            é›»åŠ›éœ€è¦äºˆæ¸¬ã€å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ç™ºé›»é‡äºˆæ¸¬ã€ã‚¹ãƒãƒ¼ãƒˆã‚°ãƒªãƒƒãƒ‰ã€
                            AI/ç”ŸæˆAIæŠ€è¡“ã®è¦³ç‚¹ã‹ã‚‰è«–æ–‡ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„ã€‚
                            åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã€é›£è§£ãªå˜èªãŒå‡ºãŸå ´åˆã¯è£œè¶³ã‚„è§£èª¬ã‚‚ä»˜ä¸
                            ã—ã¦ãã ã•ã„ã€‚ 
                            """
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1500,
                    temperature=0.3,
                    timeout=30
                )
                
                summary = response.choices[0].message.content
                if not summary or len(summary.strip()) < 50:
                    raise SummarizationError("ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ãŒçŸ­ã™ãã‚‹ã‹ç©ºã§ã™")
                    
                return summary.strip()
                
            except Exception as e:
                last_exception = e
                self.logger.warning(f"è¦ç´„ç”Ÿæˆè©¦è¡Œ{attempt + 1}å›ç›®ãŒå¤±æ•—ã—ã¾ã—ãŸ: {e}")
                
                if attempt < max_retries - 1:
                    # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                    wait_time = 2 ** attempt
                    self.logger.info(f"{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
                    time.sleep(wait_time)
                    
        raise SummarizationError(f"{max_retries}å›ã®è©¦è¡Œå¾Œã«è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ") from last_exception
    
    def _create_summary_prompt(self, paper: Dict) -> str:
        """è«–æ–‡è¦ç´„ç”¨ã®æ§‹é€ åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        
        å¼•æ•°:
            paper (Dict): è«–æ–‡ãƒ‡ãƒ¼ã‚¿è¾æ›¸
            
        æˆ»ã‚Šå€¤:
            str: LLMç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        # å¯èª­æ€§ã®ãŸã‚è‘—è€…ã‚’æœ€åˆã®3åã«åˆ¶é™
        authors = paper.get('authors', [])
        authors_str = ', '.join(authors[:3])
        if len(authors) > 3:
            authors_str += ' ã»ã‹'
        
        # é•·ã™ãã‚‹å ´åˆã¯ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’åˆ‡ã‚Šè©°ã‚
        abstract = paper.get('abstract', '')
        if len(abstract) > 2000:
            abstract = abstract[:2000] + "..."
        
        categories_str = ', '.join(paper.get('categories', []))
        
        prompt = f"""ä»¥ä¸‹ã®ç ”ç©¶è«–æ–‡ã«ã¤ã„ã¦ã€é›»åŠ›åˆ†é‡ã®è¦³ç‚¹ã‹ã‚‰æ—¥æœ¬èªã§è©³ç´°ãªè¦ç´„ã¨è§£èª¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è«–æ–‡æƒ…å ±ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {paper.get('title', 'N/A')}
è‘—è€…: {authors_str}
æŠ•ç¨¿æ—¥: {paper.get('published', 'N/A')}
åˆ†é‡: {categories_str}
PDF: {paper.get('pdf_url', 'N/A')}

ã€ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã€‘
{abstract}

ã€å‡ºåŠ›å½¢å¼ã€‘
ğŸ“„ {paper.get('title', 'N/A')}
ğŸ“ PDF: {paper.get('pdf_url', 'N/A')}

è‘—è€…: {authors_str}  
æŠ•ç¨¿æ—¥: {paper.get('published', 'N/A')}  
åˆ†é‡: {categories_str}

ğŸ¯ ç ”ç©¶ã®èƒŒæ™¯ãƒ»ç›®çš„
[ã“ã®ç ”ç©¶ãŒè§£æ±ºã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹é›»åŠ›ãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†é‡ã®èª²é¡Œã‚„èƒŒæ™¯]

ğŸ”¬ ææ¡ˆæ‰‹æ³•
[è«–æ–‡ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹å…·ä½“çš„ãªæ‰‹æ³•ã‚„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹AIæŠ€è¡“]

ğŸ“Š ä¸»ãªæˆæœãƒ»çµæœ
[å®Ÿé¨“çµæœã‚„ä¸»ãªç™ºè¦‹äº‹é …ã€äºˆæ¸¬ç²¾åº¦ã‚„æ€§èƒ½å‘ä¸Š]

ğŸ’¡ é›»åŠ›åˆ†é‡ã¸ã®å¿œç”¨
[é›»åŠ›éœ€è¦äºˆæ¸¬ã€å†ã‚¨ãƒç™ºé›»é‡äºˆæ¸¬ã€ã‚°ãƒªãƒƒãƒ‰é‹ç”¨ã¸ã®å…·ä½“çš„å¿œç”¨å¯èƒ½æ€§]

â­ é›»åŠ›åˆ†é‡é‡è¦åº¦ (5æ®µéšè©•ä¾¡)
â˜…â˜…â˜…â˜†â˜† [é›»åŠ›æ¥­ç•Œã§ã®å®Ÿç”¨æ€§ã¨é©æ–°æ€§ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ç†ç”±ã‚’è¨˜è¼‰]

ğŸ” æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ
[ä»¥ä¸‹ã®é‡è¦æŠ€è¡“é ˜åŸŸã«ãŠã‘ã‚‹æ³¨ç›®ç‚¹ã‚’æ•´ç†]
- é›»åŠ›éœ€è¦äºˆæ¸¬æŠ€è¡“: [è©²å½“ã™ã‚‹å ´åˆã®æŠ€è¡“çš„ç‰¹å¾´]
- å†ã‚¨ãƒç™ºé›»é‡äºˆæ¸¬æŠ€è¡“: [å¤ªé™½å…‰ãƒ»é¢¨åŠ›äºˆæ¸¬ã¸ã®å¿œç”¨å¯èƒ½æ€§]
- AI/ç”ŸæˆAIæŠ€è¡“: [ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹AIæ‰‹æ³•ã®ç‰¹å¾´ã¨é©æ–°æ€§]
- ã‚°ãƒªãƒƒãƒ‰åˆ†æ•£åŒ–æŠ€è¡“: [åˆ†æ•£ã‚¨ãƒãƒ«ã‚®ãƒ¼è³‡æºç®¡ç†ã¸ã®è²¢çŒ®]
- é›»åŠ›ä¾¡æ ¼äºˆæ¸¬æŠ€è¡“: [é›»åŠ›å¸‚å ´ã¸ã®å½±éŸ¿ã¨äºˆæ¸¬æ‰‹æ³•]
- ãã®ä»–é‡è¦æŠ€è¡“: [ä¸Šè¨˜ä»¥å¤–ã®é›»åŠ›åˆ†é‡ã¸ã®é‡è¦ãªè²¢çŒ®]

---
"""
        return prompt
    
    def _validate_paper_data(self, paper: Dict) -> bool:
        """è¦ç´„å‰ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        
        å¼•æ•°:
            paper (Dict): è«–æ–‡ãƒ‡ãƒ¼ã‚¿è¾æ›¸
            
        æˆ»ã‚Šå€¤:
            bool: ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ãªå ´åˆã¯Trueã€ãã†ã§ãªã‘ã‚Œã°False
        """
        required_fields = ['id', 'title']
        
        for field in required_fields:
            if field not in paper or not paper[field]:
                self.logger.warning(f"è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã«å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰'{field}'ãŒã‚ã‚Šã¾ã›ã‚“")
                return False
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒæ„å‘³ã®ã‚ã‚‹ã‚‚ã®ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆç©ºç™½ã®ã¿ã§ãªãçŸ­ã™ããªã„ï¼‰
        title = paper.get('title', '').strip()
        if len(title) < 10:
            self.logger.warning(f"è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ãŒçŸ­ã™ãã¾ã™: '{title}'")
            return False
            
        return True
    
    def _assess_power_relevance(self, paper: Dict) -> float:
        """è«–æ–‡ã®AIãƒ»äºˆæ¸¬ãƒ»IoTÃ—é›»åŠ›åˆ†é‡é–¢é€£åº¦ã‚’è©•ä¾¡
        
        4æ®µéšã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ†ã‚´ãƒªã§é–¢é€£åº¦ã‚’è©•ä¾¡ï¼š
        - æœ€é«˜é–¢é€£åº¦ï¼ˆ0.4ï¼‰: AIÃ—äºˆæ¸¬Ã—é›»åŠ›ã®èåˆæŠ€è¡“
        - é«˜é–¢é€£åº¦ï¼ˆ0.3ï¼‰: é›»åŠ›äºˆæ¸¬ãƒ»IoTç‰¹åŒ–æŠ€è¡“  
        - ä¸­é–¢é€£åº¦ï¼ˆ0.2ï¼‰: AIãƒ»äºˆæ¸¬æŠ€è¡“ä¸€èˆ¬
        - IoTåŸºç›¤ï¼ˆ0.15ï¼‰: IoTãƒ»æŠ€è¡“åŸºç›¤
        
        å¼•æ•°:
            paper (Dict): è«–æ–‡ãƒ‡ãƒ¼ã‚¿è¾æ›¸
            
        æˆ»ã‚Šå€¤:
            float: é–¢é€£åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰
        """
        title = paper.get('title', '').lower()
        abstract = paper.get('abstract', '').lower()
        text = f"{title} {abstract}"
        
        # æœ€é«˜é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿0.4ï¼‰- AIÃ—äºˆæ¸¬Ã—é›»åŠ›ã®èåˆæŠ€è¡“
        ultra_high_keywords = [
            'ai power forecast', 'machine learning energy prediction', 'deep learning power forecast',
            'neural network demand forecast', 'ai renewable energy forecast', 'smart grid ai',
            'generative ai energy', 'transformer power prediction', 'lstm energy forecast',
            'reinforcement learning grid', 'iot energy management', 'edge computing power',
            'digital twin energy', 'ai microgrid', 'federated learning energy'
        ]
        
        # é«˜é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿0.3ï¼‰- é›»åŠ›äºˆæ¸¬ãƒ»IoTç‰¹åŒ–
        high_priority_keywords = [
            'power forecast', 'demand forecast', 'energy forecast', 'wind power forecast',
            'solar forecast', 'photovoltaic forecast', 'renewable energy forecast',
            'load forecast', 'grid forecast', 'electricity demand forecast',
            'iot power monitoring', 'smart meter', 'energy iot', 'power iot',
            'edge ai energy', 'real-time power prediction', 'time series energy'
        ]
        
        # ä¸­é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿0.2ï¼‰- AIãƒ»äºˆæ¸¬æŠ€è¡“
        medium_priority_keywords = [
            'machine learning', 'deep learning', 'neural network', 'artificial intelligence',
            'prediction model', 'forecasting model', 'time series prediction',
            'lstm', 'transformer', 'cnn', 'reinforcement learning', 'generative ai',
            'anomaly detection', 'pattern recognition', 'optimization algorithm',
            'data mining', 'predictive analytics', 'computer vision'
        ]
        
        # IoTãƒ»æŠ€è¡“åŸºç›¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿0.15ï¼‰
        iot_tech_keywords = [
            'internet of things', 'iot', 'edge computing', 'fog computing',
            'wireless sensor', 'sensor network', 'smart sensor', 'embedded system',
            'real-time monitoring', 'data acquisition', 'cloud computing',
            'distributed computing', 'cyber-physical system', 'digital twin',
            'blockchain energy', 'federated learning', 'edge ai'
        ]
        
        score = 0.0
        
        # æœ€é«˜é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯ï¼ˆAIÃ—äºˆæ¸¬Ã—é›»åŠ›èåˆï¼‰
        for keyword in ultra_high_keywords:
            if keyword in text:
                score += 0.4
        
        # é«˜é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯ï¼ˆé›»åŠ›äºˆæ¸¬ãƒ»IoTç‰¹åŒ–ï¼‰
        for keyword in high_priority_keywords:
            if keyword in text:
                score += 0.3
        
        # ä¸­é–¢é€£åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯ï¼ˆAIãƒ»äºˆæ¸¬æŠ€è¡“ï¼‰
        for keyword in medium_priority_keywords:
            if keyword in text:
                score += 0.2
        
        # IoTãƒ»æŠ€è¡“åŸºç›¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        for keyword in iot_tech_keywords:
            if keyword in text:
                score += 0.15
        
        # ã‚¹ã‚³ã‚¢ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        return min(1.0, score)
    
    def batch_summarize(self, papers: list[Dict]) -> list[Dict]:
        """é€²æ—è¿½è·¡ä»˜ãã®è¤‡æ•°è«–æ–‡ã®è¦ç´„å‡¦ç†
        
        å¼•æ•°:
            papers (list[Dict]): è«–æ–‡è¾æ›¸ã®ãƒªã‚¹ãƒˆ
            
        æˆ»ã‚Šå€¤:
            list[Dict]: è¦ç´„ãŒè¿½åŠ ã•ã‚ŒãŸè«–æ–‡ã®ãƒªã‚¹ãƒˆ
        """
        if not papers:
            self.logger.warning("ãƒãƒƒãƒè¦ç´„å‡¦ç†ç”¨ã®è«–æ–‡ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        summarized_papers = []
        success_count = 0
        
        for i, paper in enumerate(papers, 1):
            self.logger.info(f"è«–æ–‡è¦ç´„ä¸­ {i}/{len(papers)}: {paper.get('title', '')[:50]}...")
            
            try:
                summarized_paper = self.summarize_paper(paper)
                summarized_papers.append(summarized_paper)
                
                if summarized_paper.get('summary_generated', False):
                    success_count += 1
                    
            except Exception as e:
                self.logger.error(f"è«–æ–‡{i}ã®è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                paper['summary_ja'] = "è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
                paper['summary_generated'] = False
                summarized_papers.append(paper)
        
        self.logger.info(f"ãƒãƒƒãƒè¦ç´„å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {success_count}/{len(papers)}ä»¶æˆåŠŸ")
        return summarized_papers


class SummarizationError(Exception):
    """è¦ç´„é–¢é€£ã‚¨ãƒ©ãƒ¼ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–"""
    pass